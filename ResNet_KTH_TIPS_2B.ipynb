{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_KTH-TIPS-2B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvDolsNKvqtW",
        "outputId": "34ba581a-d572-4179-e5d9-da67f5e1a47c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGh5X5vGv4Xw"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAeCGj4N0BqF"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1JBLkrbw9Oi"
      },
      "source": [
        "DataDir = '/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b'\n",
        "Categories = ['aluminium_foil', 'brown_bread', 'corduroy', 'cork', 'cotton', 'cracker', 'lettuce_leaf', 'linen', 'white_bread', 'wood','wool']\n",
        "Samples = ['sample_a']\n",
        "images = []\n",
        "y = np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tWjs9DRxHQc",
        "outputId": "52435f18-937e-44c6-86f8-dfcc20378c3e"
      },
      "source": [
        "for category in Categories:\n",
        "  for Sample in Samples:\n",
        "    path = os.path.join(DataDir,category)\n",
        "    path = os.path.join(path,Sample)\n",
        "    class_num = Categories.index(category)\n",
        "    print(path)\n",
        "    for imgname in os.listdir(path):\n",
        "        img = cv.imread(os.path.join(path,imgname))\n",
        "        img = cv.resize(img, (300, 300))\n",
        "        images.append(img)\n",
        "        y=np.append(y,[class_num])\n",
        "      \n",
        "        \n",
        "  \n",
        "x = np.array(images)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/aluminium_foil/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/brown_bread/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/corduroy/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cork/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cotton/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cracker/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/lettuce_leaf/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/linen/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/white_bread/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wood/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wool/sample_a\n",
            "(1188, 300, 300, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x9TwpwRxJ8z",
        "outputId": "fa159165-c77a-4459-d2d6-90baa8f04879"
      },
      "source": [
        "y = np.reshape(y,(-1,1))\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1188, 1)\n",
            "[[ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " ...\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5nbnsBlxbFh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExU0zBYFxbol"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARGVzCY-xrDw",
        "outputId": "73ee6518-c5d7-4736-d14e-edee520759c8"
      },
      "source": [
        "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "val_ds_size = tf.data.experimental.cardinality(val_ds).numpy()\n",
        "\n",
        "print('Train size:', train_ds_size)\n",
        "print('Test size:', test_ds_size)\n",
        "print('Val size:', val_ds_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 712\n",
            "Test size: 238\n",
            "Val size: 238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwwex_ijx2pI"
      },
      "source": [
        "def process_image(image,label):\n",
        "    image=tf.image.per_image_standardization(image)\n",
        "    image=tf.image.resize(image,(224,224))\n",
        "    \n",
        "    return image,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvZqHdprx3N9"
      },
      "source": [
        "train_ds = (train_ds\n",
        "          .map(process_image)\n",
        "          .shuffle(buffer_size=train_ds_size)\n",
        "          .batch(batch_size=30,drop_remainder=True)\n",
        "         )\n",
        "\n",
        "test_ds = (test_ds\n",
        "           .map(process_image)\n",
        "          .shuffle(buffer_size=test_ds_size)\n",
        "          .batch(batch_size=30,drop_remainder=True)\n",
        "         )\n",
        "\n",
        "val_ds = (val_ds\n",
        "          .map(process_image)\n",
        "          .shuffle(buffer_size=val_ds_size)\n",
        "          .batch(batch_size=30,drop_remainder=True)\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEO-xL3ix5mF"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "   \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J4_zMXqyNvH"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eINXW1XMyVYc"
      },
      "source": [
        "def ResNet50(input_shape=(224, 224, 3)):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "    \n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjRZqeT7ye3x"
      },
      "source": [
        "#Base Model\n",
        "base_model = ResNet50(input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOwapaT1yucA",
        "outputId": "895965db-4022-4522-b67a-21b180eba83f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 2048)   0           activation_48[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXeAr1Ee01zu"
      },
      "source": [
        "headModel = base_model.output\n",
        "headModel = Flatten()(headModel)\n",
        "headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel = Dense( 11,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1CXRl03012W"
      },
      "source": [
        "model = Model(inputs=base_model.input, outputs=headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkTyIBYazIEQ",
        "outputId": "3c216eee-d1fa-45ff-af60-3bf147b7db48"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.optimizers.SGD(lr=0.003),\n",
        "    metrics=['accuracy']    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSWAKwCmzJq7",
        "outputId": "0376e89c-60a1-4b95-c833-616a9e49032c"
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "          epochs=200,\n",
        "          validation_data=val_ds,\n",
        "          validation_freq=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 69s 934ms/step - loss: 2.7883 - accuracy: 0.1713 - val_loss: 2.4012 - val_accuracy: 0.1143\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 17s 724ms/step - loss: 1.9837 - accuracy: 0.2977 - val_loss: 2.4822 - val_accuracy: 0.1000\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 18s 725ms/step - loss: 1.7329 - accuracy: 0.3460 - val_loss: 2.7226 - val_accuracy: 0.0905\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 1.5710 - accuracy: 0.4196 - val_loss: 2.8306 - val_accuracy: 0.1048\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 1.1301 - accuracy: 0.6028 - val_loss: 2.9574 - val_accuracy: 0.0857\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 18s 722ms/step - loss: 1.0756 - accuracy: 0.5598 - val_loss: 3.1022 - val_accuracy: 0.0905\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.8215 - accuracy: 0.6967 - val_loss: 3.1549 - val_accuracy: 0.1810\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.6330 - accuracy: 0.7554 - val_loss: 3.1885 - val_accuracy: 0.1571\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.6063 - accuracy: 0.8034 - val_loss: 3.5447 - val_accuracy: 0.1571\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.5306 - accuracy: 0.8185 - val_loss: 3.0698 - val_accuracy: 0.2429\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.4933 - accuracy: 0.8326 - val_loss: 2.4297 - val_accuracy: 0.4571\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.3597 - accuracy: 0.8632 - val_loss: 1.4384 - val_accuracy: 0.6333\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.2851 - accuracy: 0.8973 - val_loss: 1.7842 - val_accuracy: 0.5048\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.2597 - accuracy: 0.9168 - val_loss: 1.5092 - val_accuracy: 0.6143\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.2755 - accuracy: 0.9239 - val_loss: 1.5942 - val_accuracy: 0.5762\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.4349 - accuracy: 0.8501 - val_loss: 0.7087 - val_accuracy: 0.7714\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.2024 - accuracy: 0.9306 - val_loss: 0.3642 - val_accuracy: 0.8381\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.1583 - accuracy: 0.9538 - val_loss: 0.2711 - val_accuracy: 0.9095\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.3378 - accuracy: 0.9290 - val_loss: 0.3820 - val_accuracy: 0.8381\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.1009 - accuracy: 0.9718 - val_loss: 0.1407 - val_accuracy: 0.9524\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.2282 - accuracy: 0.9328 - val_loss: 0.1078 - val_accuracy: 0.9619\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.1490 - accuracy: 0.9555 - val_loss: 0.1816 - val_accuracy: 0.9381\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.1027 - accuracy: 0.9666 - val_loss: 0.1425 - val_accuracy: 0.9619\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 0.1972 - val_accuracy: 0.9476\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0708 - accuracy: 0.9788 - val_loss: 0.2672 - val_accuracy: 0.9190\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.2525 - val_accuracy: 0.9095\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0391 - accuracy: 0.9914 - val_loss: 0.1137 - val_accuracy: 0.9714\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0425 - accuracy: 0.9917 - val_loss: 0.1806 - val_accuracy: 0.9524\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0540 - accuracy: 0.9840 - val_loss: 0.1448 - val_accuracy: 0.9476\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0955 - accuracy: 0.9723 - val_loss: 0.1373 - val_accuracy: 0.9476\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.1512 - accuracy: 0.9727 - val_loss: 0.1354 - val_accuracy: 0.9619\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0655 - accuracy: 0.9863 - val_loss: 0.0988 - val_accuracy: 0.9667\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.1773 - accuracy: 0.9492 - val_loss: 0.1224 - val_accuracy: 0.9667\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0174 - accuracy: 0.9979 - val_loss: 0.0875 - val_accuracy: 0.9810\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.1463 - accuracy: 0.9619 - val_loss: 0.1059 - val_accuracy: 0.9714\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0788 - accuracy: 0.9851 - val_loss: 0.1091 - val_accuracy: 0.9762\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0269 - accuracy: 0.9947 - val_loss: 0.0507 - val_accuracy: 0.9810\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0395 - accuracy: 0.9905 - val_loss: 0.0740 - val_accuracy: 0.9905\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 0.0586 - val_accuracy: 0.9762\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.1893 - val_accuracy: 0.9571\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0692 - accuracy: 0.9805 - val_loss: 0.0856 - val_accuracy: 0.9714\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.1586 - accuracy: 0.9699 - val_loss: 0.0915 - val_accuracy: 0.9667\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0445 - accuracy: 0.9921 - val_loss: 0.0810 - val_accuracy: 0.9667\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 17s 724ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.1027 - val_accuracy: 0.9667\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.1088 - accuracy: 0.9789 - val_loss: 0.0804 - val_accuracy: 0.9810\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0154 - accuracy: 0.9998 - val_loss: 0.0701 - val_accuracy: 0.9857\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0754 - accuracy: 0.9847 - val_loss: 0.0705 - val_accuracy: 0.9905\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0175 - accuracy: 0.9997 - val_loss: 0.0580 - val_accuracy: 0.9857\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0440 - accuracy: 0.9902 - val_loss: 0.1005 - val_accuracy: 0.9619\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.0883 - val_accuracy: 0.9714\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0738 - val_accuracy: 0.9810\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0826 - val_accuracy: 0.9714\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0528 - val_accuracy: 0.9810\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0216 - accuracy: 0.9972 - val_loss: 0.0785 - val_accuracy: 0.9667\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.0900 - val_accuracy: 0.9714\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0289 - accuracy: 0.9898 - val_loss: 0.0552 - val_accuracy: 0.9857\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 0.0444 - val_accuracy: 0.9857\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.3003 - val_accuracy: 0.9429\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0415 - accuracy: 0.9853 - val_loss: 0.1088 - val_accuracy: 0.9810\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.0775 - val_accuracy: 0.9857\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.1029 - val_accuracy: 0.9810\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.0549 - val_accuracy: 0.9905\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9857\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0370 - val_accuracy: 0.9952\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.0462 - val_accuracy: 0.9952\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0717 - val_accuracy: 0.9810\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0440 - val_accuracy: 0.9905\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9905\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 18s 759ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.0836 - val_accuracy: 0.9857\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9952\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0446 - val_accuracy: 0.9810\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0305 - accuracy: 0.9931 - val_loss: 0.0379 - val_accuracy: 0.9952\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0452 - val_accuracy: 0.9857\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0559 - accuracy: 0.9924 - val_loss: 0.0581 - val_accuracy: 0.9857\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0418 - accuracy: 0.9937 - val_loss: 0.0622 - val_accuracy: 0.9857\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9857\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0512 - val_accuracy: 0.9952\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0668 - val_accuracy: 0.9905\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0090 - accuracy: 0.9994 - val_loss: 0.0567 - val_accuracy: 0.9857\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9857\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0423 - accuracy: 0.9895 - val_loss: 0.0277 - val_accuracy: 0.9857\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0257 - accuracy: 0.9872 - val_loss: 0.0571 - val_accuracy: 0.9857\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9857\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9810\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0443 - val_accuracy: 0.9810\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0157 - accuracy: 0.9903 - val_loss: 0.0487 - val_accuracy: 0.9857\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9952\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0452 - val_accuracy: 0.9952\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0482 - val_accuracy: 0.9952\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.0366 - val_accuracy: 0.9952\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0519 - val_accuracy: 0.9905\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0747 - accuracy: 0.9801 - val_loss: 0.1001 - val_accuracy: 0.9619\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0600 - val_accuracy: 0.9857\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0426 - val_accuracy: 0.9952\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9952\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9857\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.0402 - val_accuracy: 0.9952\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0551 - val_accuracy: 0.9905\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9952\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9905\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0842 - val_accuracy: 0.9810\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0614 - accuracy: 0.9837 - val_loss: 0.1126 - val_accuracy: 0.9762\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0546 - val_accuracy: 0.9857\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9810\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0417 - val_accuracy: 0.9905\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9952\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0422 - val_accuracy: 0.9905\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0448 - val_accuracy: 0.9952\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9952\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0333 - val_accuracy: 0.9905\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0367 - val_accuracy: 0.9810\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0811 - val_accuracy: 0.9857\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0559 - val_accuracy: 0.9857\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0850 - val_accuracy: 0.9810\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9857\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0370 - val_accuracy: 0.9952\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1091 - val_accuracy: 0.9714\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.0241 - val_accuracy: 0.9857\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 18s 722ms/step - loss: 0.0063 - accuracy: 0.9958 - val_loss: 0.0474 - val_accuracy: 0.9952\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9810\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.1916 - accuracy: 0.9438 - val_loss: 0.0920 - val_accuracy: 0.9810\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0881 - val_accuracy: 0.9857\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9857\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9857\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.1189 - val_accuracy: 0.9810\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.1042 - val_accuracy: 0.9762\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0840 - val_accuracy: 0.9810\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 18s 723ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9857\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9857\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0227 - accuracy: 0.9947 - val_loss: 0.0639 - val_accuracy: 0.9762\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9905\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0089 - accuracy: 0.9941 - val_loss: 0.1414 - val_accuracy: 0.9762\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0495 - val_accuracy: 0.9857\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.8731 - val_accuracy: 0.8905\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0359 - accuracy: 0.9927 - val_loss: 0.1671 - val_accuracy: 0.9429\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0496 - val_accuracy: 0.9810\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0408 - val_accuracy: 0.9857\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0055 - accuracy: 0.9960 - val_loss: 0.0550 - val_accuracy: 0.9857\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 18s 726ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9905\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9952\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 0.9905\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0037 - accuracy: 0.9979 - val_loss: 0.0569 - val_accuracy: 0.9905\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.0528 - val_accuracy: 0.9905\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0564 - val_accuracy: 0.9857\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0414 - val_accuracy: 0.9810\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 18s 759ms/step - loss: 0.0065 - accuracy: 0.9969 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 17s 721ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9905\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9905\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 17s 720ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0161 - val_accuracy: 0.9952\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0108 - val_accuracy: 0.9952\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9952\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9952\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 18s 762ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9905\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 18s 722ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9905\n",
            "Epoch 158/200\n",
            "20/23 [=========================>....] - ETA: 1s - loss: 0.0016 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R7vmsEnzUyY"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Testing accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoVdqJ_hzXtQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}