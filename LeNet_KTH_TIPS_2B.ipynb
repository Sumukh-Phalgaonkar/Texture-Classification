{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet_KTH-TIPS-2B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-Qx1QKvQul",
        "outputId": "c13464d1-c1cd-4788-c80d-1d844136e4bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKm7M2QnvTuU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckYXUTXJvjuF"
      },
      "source": [
        "DataDir = '/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b'\n",
        "Categories = ['aluminium_foil', 'brown_bread', 'corduroy', 'cork', 'cotton', 'cracker', 'lettuce_leaf', 'linen', 'white_bread', 'wood','wool']\n",
        "Samples = ['sample_a','sample_b','sample_c', 'sample_d']\n",
        "images = []\n",
        "y = np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4oZSf3kvyaF",
        "outputId": "cc55b3b6-dce1-46eb-813e-0b760255a42a"
      },
      "source": [
        "for category in Categories:\n",
        "  for Sample in Samples:\n",
        "    path = os.path.join(DataDir,category)\n",
        "    path = os.path.join(path,Sample)\n",
        "    class_num = Categories.index(category)\n",
        "    print(path)\n",
        "    for imgname in os.listdir(path):\n",
        "        img = cv.imread(os.path.join(path,imgname))\n",
        "        img = cv.resize(img, (300, 300))\n",
        "        images.append(img)\n",
        "        y=np.append(y,[class_num])\n",
        "      \n",
        "        \n",
        "  \n",
        "x = np.array(images)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/aluminium_foil/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/aluminium_foil/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/aluminium_foil/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/aluminium_foil/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/brown_bread/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/brown_bread/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/brown_bread/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/brown_bread/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/corduroy/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/corduroy/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/corduroy/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/corduroy/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cork/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cork/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cork/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cork/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cotton/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cotton/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cotton/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cotton/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cracker/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cracker/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cracker/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/cracker/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/lettuce_leaf/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/lettuce_leaf/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/lettuce_leaf/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/lettuce_leaf/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/linen/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/linen/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/linen/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/linen/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/white_bread/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/white_bread/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/white_bread/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/white_bread/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wood/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wood/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wood/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wood/sample_d\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wool/sample_a\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wool/sample_b\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wool/sample_c\n",
            "/content/drive/MyDrive/PS 1/Datasets/KTH-TIPS-2B/KTH-TIPS2-b/wool/sample_d\n",
            "(4752, 300, 300, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF_K2kXGv8VN",
        "outputId": "35bd797b-27c7-4c66-ce9f-e839964f4b11"
      },
      "source": [
        "y = np.reshape(y,(-1,1))\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4752, 1)\n",
            "[[ 0.]\n",
            " [ 0.]\n",
            " [ 0.]\n",
            " ...\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "012nLjLjxgNV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKDv4-e4koCi"
      },
      "source": [
        "X_train = X_train /255\n",
        "X_test = X_test/255\n",
        "X_val =X_val/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZrzHiHfxp3j",
        "outputId": "6040192d-c2a3-4089-d8ec-86839ca26bf6"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(712, 300, 300, 3)\n",
            "(238, 300, 300, 3)\n",
            "(238, 300, 300, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTjmvLdqxuru",
        "outputId": "dcfc56db-517b-4b8b-ff83-9f6db7a430c7"
      },
      "source": [
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(712, 1)\n",
            "(238, 1)\n",
            "(238, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbFqQa5Mxxm2"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Toi0kR7x0Mz",
        "outputId": "fe608f5c-d9ef-4144-e86c-aba418221b9b"
      },
      "source": [
        "print(train_ds)\n",
        "print(train_ds)\n",
        "print(val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: ((300, 300, 3), (1,)), types: (tf.uint8, tf.float64)>\n",
            "<TensorSliceDataset shapes: ((300, 300, 3), (1,)), types: (tf.uint8, tf.float64)>\n",
            "<TensorSliceDataset shapes: ((300, 300, 3), (1,)), types: (tf.uint8, tf.float64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p__BOJlwx3hN",
        "outputId": "ea2903ba-bfb7-4b5e-e8bb-7309cc94b3e9"
      },
      "source": [
        "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "val_ds_size = tf.data.experimental.cardinality(val_ds).numpy()\n",
        "\n",
        "print('Train size:', train_ds_size)\n",
        "print('Test size:', test_ds_size)\n",
        "print('Val size:', val_ds_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 712\n",
            "Test size: 238\n",
            "Val size: 238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXbtxmQEBdX-"
      },
      "source": [
        "def process_image(image,label):\n",
        "    image=tf.image.per_image_standardization(image)\n",
        "    image=tf.image.resize(image,(227,227))\n",
        "    \n",
        "    return image,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Spgdt--BdkN"
      },
      "source": [
        "train_ds = (train_ds\n",
        "          .map(process_image)\n",
        "          .shuffle(buffer_size=train_ds_size)\n",
        "          .batch(batch_size=30,drop_remainder=True)\n",
        "         )\n",
        "\n",
        "test_ds = (test_ds\n",
        "           .map(process_image)\n",
        "          .shuffle(buffer_size=test_ds_size)\n",
        "          .batch(batch_size=30,drop_remainder=True)\n",
        "         )\n",
        "\n",
        "val_ds = (val_ds\n",
        "          .map(process_image)\n",
        "          .shuffle(buffer_size=val_ds_size)\n",
        "          .batch(batch_size=30,drop_remainder=True)\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpHdoLYax7Qb"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers import Conv2D, Activation, Input, concatenate, Lambda, ZeroPadding2D, MaxPooling2D, Layer, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.backend import l2_normalize, expand_dims, variable, constant\n",
        "import cv2, numpy as np\n",
        "##from netvladlayer import NetVLAD\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCFyDuy0hXxU"
      },
      "source": [
        "lenet_5_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=X_train[0].shape, padding='same'), #C1\n",
        "    keras.layers.AveragePooling2D(), #S2\n",
        "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C3\n",
        "    keras.layers.AveragePooling2D(), #S4\n",
        "    keras.layers.Flatten(), #Flatten\n",
        "    keras.layers.Dense(120, activation='tanh'), #C5\n",
        "    keras.layers.Dense(84, activation='tanh'), #F6\n",
        "    keras.layers.Dense(11, activation='softmax') #Output layer\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTO3Ex3shX2X",
        "outputId": "7c254e48-a30a-4108-f564-6d27457d18a6"
      },
      "source": [
        "lenet_5_model.compile(optimizer=tf.optimizers.SGD(lr=0.00003), loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wbBiRe_hX5G"
      },
      "source": [
        "history= lenet_5_model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQZUZds6hX7i",
        "outputId": "c411445b-67a7-40f5-f0db-62eedd2cb8b8"
      },
      "source": [
        "history= lenet_5_model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 3s 85ms/step - loss: 2.6261 - accuracy: 0.0934 - val_loss: 2.4881 - val_accuracy: 0.1807\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.1976 - accuracy: 0.2344 - val_loss: 1.9910 - val_accuracy: 0.3866\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9955 - accuracy: 0.3128 - val_loss: 1.8580 - val_accuracy: 0.3235\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8235 - accuracy: 0.3376 - val_loss: 1.8826 - val_accuracy: 0.2269\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7121 - accuracy: 0.3681 - val_loss: 2.1593 - val_accuracy: 0.2437\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6361 - accuracy: 0.4477 - val_loss: 2.0011 - val_accuracy: 0.2269\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6762 - accuracy: 0.3557 - val_loss: 1.7649 - val_accuracy: 0.2815\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 1.4687 - accuracy: 0.4627 - val_loss: 2.0524 - val_accuracy: 0.3403\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4169 - accuracy: 0.5157 - val_loss: 1.2407 - val_accuracy: 0.6681\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2834 - accuracy: 0.5825 - val_loss: 1.1814 - val_accuracy: 0.6975\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1760 - accuracy: 0.6201 - val_loss: 1.4305 - val_accuracy: 0.4580\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2955 - accuracy: 0.5345 - val_loss: 0.9859 - val_accuracy: 0.7353\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0184 - accuracy: 0.6899 - val_loss: 2.1353 - val_accuracy: 0.3319\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1486 - accuracy: 0.6444 - val_loss: 1.1030 - val_accuracy: 0.6891\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0070 - accuracy: 0.6865 - val_loss: 1.0187 - val_accuracy: 0.7017\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.9141 - accuracy: 0.7444 - val_loss: 1.3912 - val_accuracy: 0.4202\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2277 - accuracy: 0.5619 - val_loss: 2.0416 - val_accuracy: 0.2689\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0541 - accuracy: 0.7028 - val_loss: 0.8999 - val_accuracy: 0.7143\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.7894 - accuracy: 0.7949 - val_loss: 0.8414 - val_accuracy: 0.7941\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.7264 - accuracy: 0.8163 - val_loss: 0.8298 - val_accuracy: 0.7101\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.7310 - accuracy: 0.8170 - val_loss: 0.8909 - val_accuracy: 0.7311\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.8325 - accuracy: 0.7392 - val_loss: 1.5966 - val_accuracy: 0.4244\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.9070 - accuracy: 0.7135 - val_loss: 0.6957 - val_accuracy: 0.8445\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.6228 - accuracy: 0.8700 - val_loss: 0.7448 - val_accuracy: 0.7941\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.7308 - accuracy: 0.7922 - val_loss: 0.6917 - val_accuracy: 0.8109\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.6131 - accuracy: 0.8470 - val_loss: 1.2311 - val_accuracy: 0.4748\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.9223 - accuracy: 0.6906 - val_loss: 0.6509 - val_accuracy: 0.8193\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.5192 - accuracy: 0.8947 - val_loss: 0.7158 - val_accuracy: 0.8277\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.5353 - accuracy: 0.8889 - val_loss: 0.5959 - val_accuracy: 0.8739\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.5021 - accuracy: 0.9003 - val_loss: 0.6026 - val_accuracy: 0.8361\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4645 - accuracy: 0.9094 - val_loss: 0.7459 - val_accuracy: 0.8067\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.5014 - accuracy: 0.8998 - val_loss: 0.5563 - val_accuracy: 0.8697\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4364 - accuracy: 0.9218 - val_loss: 1.7029 - val_accuracy: 0.4202\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.7304 - accuracy: 0.7774 - val_loss: 0.6473 - val_accuracy: 0.8067\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.5245 - accuracy: 0.8746 - val_loss: 0.5240 - val_accuracy: 0.8613\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3941 - accuracy: 0.9214 - val_loss: 0.8607 - val_accuracy: 0.7017\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.3800 - accuracy: 0.9304 - val_loss: 1.0729 - val_accuracy: 0.7227\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.6018 - accuracy: 0.8231 - val_loss: 0.5067 - val_accuracy: 0.8613\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3766 - accuracy: 0.9221 - val_loss: 0.7779 - val_accuracy: 0.7563\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.3880 - accuracy: 0.8983 - val_loss: 0.5889 - val_accuracy: 0.7983\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3680 - accuracy: 0.9114 - val_loss: 0.5898 - val_accuracy: 0.7983\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3062 - accuracy: 0.9477 - val_loss: 0.7938 - val_accuracy: 0.7479\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4348 - accuracy: 0.8972 - val_loss: 0.4590 - val_accuracy: 0.8655\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.2969 - accuracy: 0.9434 - val_loss: 0.4983 - val_accuracy: 0.8529\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.2863 - accuracy: 0.9469 - val_loss: 0.4703 - val_accuracy: 0.8824\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.2837 - accuracy: 0.9490 - val_loss: 0.5038 - val_accuracy: 0.8403\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.2927 - accuracy: 0.9286 - val_loss: 1.4902 - val_accuracy: 0.5126\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.5234 - accuracy: 0.8452 - val_loss: 0.5275 - val_accuracy: 0.8529\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.2673 - accuracy: 0.9517 - val_loss: 0.4226 - val_accuracy: 0.8739\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.2571 - accuracy: 0.9433 - val_loss: 0.4044 - val_accuracy: 0.8782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl4s42OYhX-6",
        "outputId": "6d8911f2-18a9-4808-a186-8fbae49167eb"
      },
      "source": [
        "history= lenet_5_model.fit(X_train, y_train, epochs=500, validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "23/23 [==============================] - 3s 85ms/step - loss: 2.4418 - accuracy: 0.0756 - val_loss: 2.4116 - val_accuracy: 0.1176\n",
            "Epoch 2/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.4071 - accuracy: 0.1257 - val_loss: 2.3865 - val_accuracy: 0.1092\n",
            "Epoch 3/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.3782 - accuracy: 0.1550 - val_loss: 2.3692 - val_accuracy: 0.1471\n",
            "Epoch 4/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.3594 - accuracy: 0.1806 - val_loss: 2.3543 - val_accuracy: 0.1176\n",
            "Epoch 5/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.3420 - accuracy: 0.1682 - val_loss: 2.3421 - val_accuracy: 0.0924\n",
            "Epoch 6/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.3443 - accuracy: 0.1203 - val_loss: 2.3293 - val_accuracy: 0.1050\n",
            "Epoch 7/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.3160 - accuracy: 0.1428 - val_loss: 2.3177 - val_accuracy: 0.1008\n",
            "Epoch 8/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.3078 - accuracy: 0.1274 - val_loss: 2.3069 - val_accuracy: 0.0882\n",
            "Epoch 9/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2866 - accuracy: 0.1128 - val_loss: 2.2953 - val_accuracy: 0.1429\n",
            "Epoch 10/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2821 - accuracy: 0.1654 - val_loss: 2.2840 - val_accuracy: 0.1639\n",
            "Epoch 11/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.2777 - accuracy: 0.2089 - val_loss: 2.2731 - val_accuracy: 0.1933\n",
            "Epoch 12/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2540 - accuracy: 0.2230 - val_loss: 2.2619 - val_accuracy: 0.2395\n",
            "Epoch 13/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.2581 - accuracy: 0.2657 - val_loss: 2.2521 - val_accuracy: 0.2647\n",
            "Epoch 14/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2377 - accuracy: 0.2603 - val_loss: 2.2416 - val_accuracy: 0.2731\n",
            "Epoch 15/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.2187 - accuracy: 0.3018 - val_loss: 2.2312 - val_accuracy: 0.2773\n",
            "Epoch 16/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2235 - accuracy: 0.2704 - val_loss: 2.2210 - val_accuracy: 0.2857\n",
            "Epoch 17/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2009 - accuracy: 0.3085 - val_loss: 2.2120 - val_accuracy: 0.2899\n",
            "Epoch 18/500\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 2.1869 - accuracy: 0.3110 - val_loss: 2.2018 - val_accuracy: 0.2899\n",
            "Epoch 19/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.1988 - accuracy: 0.2654 - val_loss: 2.1923 - val_accuracy: 0.3109\n",
            "Epoch 20/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.1643 - accuracy: 0.2974 - val_loss: 2.1835 - val_accuracy: 0.2773\n",
            "Epoch 21/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.1681 - accuracy: 0.2707 - val_loss: 2.1744 - val_accuracy: 0.2899\n",
            "Epoch 22/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.1704 - accuracy: 0.2652 - val_loss: 2.1648 - val_accuracy: 0.2773\n",
            "Epoch 23/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.1381 - accuracy: 0.3062 - val_loss: 2.1556 - val_accuracy: 0.2983\n",
            "Epoch 24/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.1454 - accuracy: 0.2892 - val_loss: 2.1464 - val_accuracy: 0.2857\n",
            "Epoch 25/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.1143 - accuracy: 0.3125 - val_loss: 2.1376 - val_accuracy: 0.2983\n",
            "Epoch 26/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.1072 - accuracy: 0.3318 - val_loss: 2.1301 - val_accuracy: 0.3151\n",
            "Epoch 27/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.1148 - accuracy: 0.3073 - val_loss: 2.1212 - val_accuracy: 0.3109\n",
            "Epoch 28/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.0933 - accuracy: 0.3346 - val_loss: 2.1128 - val_accuracy: 0.3067\n",
            "Epoch 29/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.1140 - accuracy: 0.2984 - val_loss: 2.1050 - val_accuracy: 0.3067\n",
            "Epoch 30/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0921 - accuracy: 0.3130 - val_loss: 2.0981 - val_accuracy: 0.2941\n",
            "Epoch 31/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0772 - accuracy: 0.2914 - val_loss: 2.0911 - val_accuracy: 0.3067\n",
            "Epoch 32/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0933 - accuracy: 0.2901 - val_loss: 2.0825 - val_accuracy: 0.3025\n",
            "Epoch 33/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0818 - accuracy: 0.2993 - val_loss: 2.0761 - val_accuracy: 0.2815\n",
            "Epoch 34/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.0594 - accuracy: 0.3071 - val_loss: 2.0688 - val_accuracy: 0.2731\n",
            "Epoch 35/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.0668 - accuracy: 0.2998 - val_loss: 2.0620 - val_accuracy: 0.3067\n",
            "Epoch 36/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0407 - accuracy: 0.3290 - val_loss: 2.0555 - val_accuracy: 0.3067\n",
            "Epoch 37/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0232 - accuracy: 0.3377 - val_loss: 2.0498 - val_accuracy: 0.3235\n",
            "Epoch 38/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0384 - accuracy: 0.3279 - val_loss: 2.0430 - val_accuracy: 0.3067\n",
            "Epoch 39/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0427 - accuracy: 0.3082 - val_loss: 2.0369 - val_accuracy: 0.3235\n",
            "Epoch 40/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.0155 - accuracy: 0.3108 - val_loss: 2.0310 - val_accuracy: 0.3277\n",
            "Epoch 41/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9815 - accuracy: 0.3658 - val_loss: 2.0249 - val_accuracy: 0.3109\n",
            "Epoch 42/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.9825 - accuracy: 0.3585 - val_loss: 2.0189 - val_accuracy: 0.2941\n",
            "Epoch 43/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.0008 - accuracy: 0.3178 - val_loss: 2.0127 - val_accuracy: 0.3277\n",
            "Epoch 44/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9768 - accuracy: 0.3934 - val_loss: 2.0068 - val_accuracy: 0.3361\n",
            "Epoch 45/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9662 - accuracy: 0.3692 - val_loss: 2.0008 - val_accuracy: 0.3361\n",
            "Epoch 46/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9574 - accuracy: 0.3838 - val_loss: 1.9949 - val_accuracy: 0.3277\n",
            "Epoch 47/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9998 - accuracy: 0.3310 - val_loss: 1.9891 - val_accuracy: 0.3235\n",
            "Epoch 48/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9655 - accuracy: 0.3846 - val_loss: 1.9838 - val_accuracy: 0.3235\n",
            "Epoch 49/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9706 - accuracy: 0.3432 - val_loss: 1.9788 - val_accuracy: 0.3235\n",
            "Epoch 50/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9573 - accuracy: 0.3175 - val_loss: 1.9738 - val_accuracy: 0.3235\n",
            "Epoch 51/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9721 - accuracy: 0.3540 - val_loss: 1.9693 - val_accuracy: 0.3361\n",
            "Epoch 52/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.9584 - accuracy: 0.3687 - val_loss: 1.9641 - val_accuracy: 0.3319\n",
            "Epoch 53/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9381 - accuracy: 0.3558 - val_loss: 1.9586 - val_accuracy: 0.3319\n",
            "Epoch 54/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9421 - accuracy: 0.3072 - val_loss: 1.9539 - val_accuracy: 0.3361\n",
            "Epoch 55/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.9296 - accuracy: 0.3519 - val_loss: 1.9479 - val_accuracy: 0.3361\n",
            "Epoch 56/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9504 - accuracy: 0.3629 - val_loss: 1.9437 - val_accuracy: 0.3403\n",
            "Epoch 57/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9296 - accuracy: 0.3844 - val_loss: 1.9397 - val_accuracy: 0.3445\n",
            "Epoch 58/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9515 - accuracy: 0.3480 - val_loss: 1.9352 - val_accuracy: 0.3403\n",
            "Epoch 59/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9202 - accuracy: 0.3434 - val_loss: 1.9303 - val_accuracy: 0.3403\n",
            "Epoch 60/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.9108 - accuracy: 0.3627 - val_loss: 1.9255 - val_accuracy: 0.3445\n",
            "Epoch 61/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.9076 - accuracy: 0.3659 - val_loss: 1.9214 - val_accuracy: 0.3445\n",
            "Epoch 62/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8884 - accuracy: 0.3889 - val_loss: 1.9169 - val_accuracy: 0.3445\n",
            "Epoch 63/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.8924 - accuracy: 0.3766 - val_loss: 1.9125 - val_accuracy: 0.3403\n",
            "Epoch 64/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8952 - accuracy: 0.3662 - val_loss: 1.9077 - val_accuracy: 0.3445\n",
            "Epoch 65/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8660 - accuracy: 0.3757 - val_loss: 1.9034 - val_accuracy: 0.3403\n",
            "Epoch 66/500\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 1.8879 - accuracy: 0.3593 - val_loss: 1.8996 - val_accuracy: 0.3445\n",
            "Epoch 67/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8960 - accuracy: 0.3737 - val_loss: 1.8951 - val_accuracy: 0.3529\n",
            "Epoch 68/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8888 - accuracy: 0.3749 - val_loss: 1.8914 - val_accuracy: 0.3655\n",
            "Epoch 69/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8503 - accuracy: 0.4155 - val_loss: 1.8878 - val_accuracy: 0.3571\n",
            "Epoch 70/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8677 - accuracy: 0.3957 - val_loss: 1.8836 - val_accuracy: 0.3571\n",
            "Epoch 71/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.8487 - accuracy: 0.3794 - val_loss: 1.8797 - val_accuracy: 0.3571\n",
            "Epoch 72/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8369 - accuracy: 0.4026 - val_loss: 1.8762 - val_accuracy: 0.3613\n",
            "Epoch 73/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8870 - accuracy: 0.3663 - val_loss: 1.8725 - val_accuracy: 0.3529\n",
            "Epoch 74/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8410 - accuracy: 0.3689 - val_loss: 1.8691 - val_accuracy: 0.3571\n",
            "Epoch 75/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8498 - accuracy: 0.4080 - val_loss: 1.8657 - val_accuracy: 0.3908\n",
            "Epoch 76/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.8621 - accuracy: 0.3808 - val_loss: 1.8617 - val_accuracy: 0.3739\n",
            "Epoch 77/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8509 - accuracy: 0.3825 - val_loss: 1.8574 - val_accuracy: 0.3782\n",
            "Epoch 78/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8371 - accuracy: 0.3874 - val_loss: 1.8541 - val_accuracy: 0.3908\n",
            "Epoch 79/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8310 - accuracy: 0.4059 - val_loss: 1.8494 - val_accuracy: 0.3908\n",
            "Epoch 80/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8217 - accuracy: 0.3902 - val_loss: 1.8461 - val_accuracy: 0.3782\n",
            "Epoch 81/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8127 - accuracy: 0.3959 - val_loss: 1.8427 - val_accuracy: 0.3697\n",
            "Epoch 82/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.7997 - accuracy: 0.4043 - val_loss: 1.8390 - val_accuracy: 0.3866\n",
            "Epoch 83/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.8397 - accuracy: 0.4064 - val_loss: 1.8347 - val_accuracy: 0.3824\n",
            "Epoch 84/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8017 - accuracy: 0.4183 - val_loss: 1.8313 - val_accuracy: 0.3866\n",
            "Epoch 85/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.7753 - accuracy: 0.4465 - val_loss: 1.8281 - val_accuracy: 0.4034\n",
            "Epoch 86/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8067 - accuracy: 0.4018 - val_loss: 1.8253 - val_accuracy: 0.4118\n",
            "Epoch 87/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.8402 - accuracy: 0.3758 - val_loss: 1.8224 - val_accuracy: 0.4076\n",
            "Epoch 88/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7909 - accuracy: 0.4366 - val_loss: 1.8182 - val_accuracy: 0.4202\n",
            "Epoch 89/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.7947 - accuracy: 0.4125 - val_loss: 1.8146 - val_accuracy: 0.4034\n",
            "Epoch 90/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.7909 - accuracy: 0.4061 - val_loss: 1.8113 - val_accuracy: 0.3908\n",
            "Epoch 91/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7617 - accuracy: 0.4393 - val_loss: 1.8073 - val_accuracy: 0.3950\n",
            "Epoch 92/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.8099 - accuracy: 0.3988 - val_loss: 1.8036 - val_accuracy: 0.3992\n",
            "Epoch 93/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7579 - accuracy: 0.4146 - val_loss: 1.8008 - val_accuracy: 0.4034\n",
            "Epoch 94/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7703 - accuracy: 0.4271 - val_loss: 1.7975 - val_accuracy: 0.4118\n",
            "Epoch 95/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.7802 - accuracy: 0.4428 - val_loss: 1.7942 - val_accuracy: 0.4328\n",
            "Epoch 96/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7695 - accuracy: 0.4193 - val_loss: 1.7907 - val_accuracy: 0.4412\n",
            "Epoch 97/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7712 - accuracy: 0.4238 - val_loss: 1.7873 - val_accuracy: 0.4370\n",
            "Epoch 98/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7310 - accuracy: 0.4323 - val_loss: 1.7846 - val_accuracy: 0.4454\n",
            "Epoch 99/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.7730 - accuracy: 0.4184 - val_loss: 1.7818 - val_accuracy: 0.4538\n",
            "Epoch 100/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7556 - accuracy: 0.4334 - val_loss: 1.7780 - val_accuracy: 0.4496\n",
            "Epoch 101/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7484 - accuracy: 0.4478 - val_loss: 1.7740 - val_accuracy: 0.4580\n",
            "Epoch 102/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7614 - accuracy: 0.4719 - val_loss: 1.7710 - val_accuracy: 0.4580\n",
            "Epoch 103/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7333 - accuracy: 0.4577 - val_loss: 1.7679 - val_accuracy: 0.4454\n",
            "Epoch 104/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7456 - accuracy: 0.4459 - val_loss: 1.7654 - val_accuracy: 0.4370\n",
            "Epoch 105/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7208 - accuracy: 0.4433 - val_loss: 1.7617 - val_accuracy: 0.4412\n",
            "Epoch 106/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.7213 - accuracy: 0.4500 - val_loss: 1.7586 - val_accuracy: 0.4454\n",
            "Epoch 107/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7122 - accuracy: 0.4532 - val_loss: 1.7554 - val_accuracy: 0.4538\n",
            "Epoch 108/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7240 - accuracy: 0.4684 - val_loss: 1.7521 - val_accuracy: 0.4412\n",
            "Epoch 109/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7134 - accuracy: 0.4547 - val_loss: 1.7493 - val_accuracy: 0.4454\n",
            "Epoch 110/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7421 - accuracy: 0.4265 - val_loss: 1.7458 - val_accuracy: 0.4580\n",
            "Epoch 111/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.7283 - accuracy: 0.4400 - val_loss: 1.7434 - val_accuracy: 0.4622\n",
            "Epoch 112/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6846 - accuracy: 0.4886 - val_loss: 1.7403 - val_accuracy: 0.4622\n",
            "Epoch 113/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.7247 - accuracy: 0.4611 - val_loss: 1.7373 - val_accuracy: 0.4622\n",
            "Epoch 114/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.7029 - accuracy: 0.4488 - val_loss: 1.7343 - val_accuracy: 0.4580\n",
            "Epoch 115/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.6914 - accuracy: 0.4679 - val_loss: 1.7316 - val_accuracy: 0.4706\n",
            "Epoch 116/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7069 - accuracy: 0.4390 - val_loss: 1.7291 - val_accuracy: 0.4706\n",
            "Epoch 117/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6890 - accuracy: 0.4876 - val_loss: 1.7265 - val_accuracy: 0.4748\n",
            "Epoch 118/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7023 - accuracy: 0.4761 - val_loss: 1.7235 - val_accuracy: 0.4580\n",
            "Epoch 119/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6641 - accuracy: 0.4736 - val_loss: 1.7211 - val_accuracy: 0.4664\n",
            "Epoch 120/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7045 - accuracy: 0.4608 - val_loss: 1.7184 - val_accuracy: 0.4790\n",
            "Epoch 121/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.6991 - accuracy: 0.4546 - val_loss: 1.7154 - val_accuracy: 0.4832\n",
            "Epoch 122/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6834 - accuracy: 0.4722 - val_loss: 1.7123 - val_accuracy: 0.4832\n",
            "Epoch 123/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7028 - accuracy: 0.4472 - val_loss: 1.7093 - val_accuracy: 0.4958\n",
            "Epoch 124/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6687 - accuracy: 0.4894 - val_loss: 1.7066 - val_accuracy: 0.4958\n",
            "Epoch 125/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6924 - accuracy: 0.4524 - val_loss: 1.7033 - val_accuracy: 0.4958\n",
            "Epoch 126/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6911 - accuracy: 0.4624 - val_loss: 1.7013 - val_accuracy: 0.4916\n",
            "Epoch 127/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6442 - accuracy: 0.4968 - val_loss: 1.6981 - val_accuracy: 0.4958\n",
            "Epoch 128/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6551 - accuracy: 0.4798 - val_loss: 1.6952 - val_accuracy: 0.4832\n",
            "Epoch 129/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6476 - accuracy: 0.4788 - val_loss: 1.6920 - val_accuracy: 0.4916\n",
            "Epoch 130/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7139 - accuracy: 0.4646 - val_loss: 1.6894 - val_accuracy: 0.4874\n",
            "Epoch 131/500\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 1.6525 - accuracy: 0.4724 - val_loss: 1.6875 - val_accuracy: 0.4916\n",
            "Epoch 132/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.6790 - accuracy: 0.4787 - val_loss: 1.6851 - val_accuracy: 0.4832\n",
            "Epoch 133/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.6364 - accuracy: 0.5069 - val_loss: 1.6826 - val_accuracy: 0.4874\n",
            "Epoch 134/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6573 - accuracy: 0.4787 - val_loss: 1.6800 - val_accuracy: 0.5000\n",
            "Epoch 135/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6034 - accuracy: 0.5004 - val_loss: 1.6776 - val_accuracy: 0.4958\n",
            "Epoch 136/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.6500 - accuracy: 0.4970 - val_loss: 1.6748 - val_accuracy: 0.5042\n",
            "Epoch 137/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6423 - accuracy: 0.4710 - val_loss: 1.6720 - val_accuracy: 0.5042\n",
            "Epoch 138/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6174 - accuracy: 0.4942 - val_loss: 1.6694 - val_accuracy: 0.5168\n",
            "Epoch 139/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6199 - accuracy: 0.5051 - val_loss: 1.6669 - val_accuracy: 0.5126\n",
            "Epoch 140/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6179 - accuracy: 0.5456 - val_loss: 1.6642 - val_accuracy: 0.5168\n",
            "Epoch 141/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6021 - accuracy: 0.5253 - val_loss: 1.6610 - val_accuracy: 0.5126\n",
            "Epoch 142/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6476 - accuracy: 0.4886 - val_loss: 1.6592 - val_accuracy: 0.5168\n",
            "Epoch 143/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6187 - accuracy: 0.5065 - val_loss: 1.6576 - val_accuracy: 0.5210\n",
            "Epoch 144/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6092 - accuracy: 0.5389 - val_loss: 1.6543 - val_accuracy: 0.5294\n",
            "Epoch 145/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6202 - accuracy: 0.5372 - val_loss: 1.6513 - val_accuracy: 0.5546\n",
            "Epoch 146/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6187 - accuracy: 0.5293 - val_loss: 1.6484 - val_accuracy: 0.5588\n",
            "Epoch 147/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6259 - accuracy: 0.5485 - val_loss: 1.6449 - val_accuracy: 0.5420\n",
            "Epoch 148/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.6206 - accuracy: 0.5601 - val_loss: 1.6425 - val_accuracy: 0.5462\n",
            "Epoch 149/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6051 - accuracy: 0.5554 - val_loss: 1.6399 - val_accuracy: 0.5420\n",
            "Epoch 150/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5824 - accuracy: 0.5454 - val_loss: 1.6375 - val_accuracy: 0.5378\n",
            "Epoch 151/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5902 - accuracy: 0.5263 - val_loss: 1.6362 - val_accuracy: 0.5672\n",
            "Epoch 152/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5823 - accuracy: 0.5651 - val_loss: 1.6333 - val_accuracy: 0.5294\n",
            "Epoch 153/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5936 - accuracy: 0.5311 - val_loss: 1.6306 - val_accuracy: 0.5294\n",
            "Epoch 154/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5938 - accuracy: 0.5612 - val_loss: 1.6283 - val_accuracy: 0.5378\n",
            "Epoch 155/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5995 - accuracy: 0.5715 - val_loss: 1.6256 - val_accuracy: 0.5378\n",
            "Epoch 156/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5859 - accuracy: 0.5856 - val_loss: 1.6230 - val_accuracy: 0.5252\n",
            "Epoch 157/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6093 - accuracy: 0.5480 - val_loss: 1.6216 - val_accuracy: 0.5588\n",
            "Epoch 158/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5666 - accuracy: 0.5968 - val_loss: 1.6187 - val_accuracy: 0.5630\n",
            "Epoch 159/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5652 - accuracy: 0.5698 - val_loss: 1.6163 - val_accuracy: 0.5672\n",
            "Epoch 160/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.6026 - accuracy: 0.5792 - val_loss: 1.6134 - val_accuracy: 0.5672\n",
            "Epoch 161/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5948 - accuracy: 0.5675 - val_loss: 1.6112 - val_accuracy: 0.5672\n",
            "Epoch 162/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5747 - accuracy: 0.5766 - val_loss: 1.6086 - val_accuracy: 0.5714\n",
            "Epoch 163/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5650 - accuracy: 0.6150 - val_loss: 1.6059 - val_accuracy: 0.5714\n",
            "Epoch 164/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5818 - accuracy: 0.5666 - val_loss: 1.6040 - val_accuracy: 0.5672\n",
            "Epoch 165/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5707 - accuracy: 0.5753 - val_loss: 1.6012 - val_accuracy: 0.5672\n",
            "Epoch 166/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5655 - accuracy: 0.6051 - val_loss: 1.5991 - val_accuracy: 0.5672\n",
            "Epoch 167/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5658 - accuracy: 0.5998 - val_loss: 1.5966 - val_accuracy: 0.5672\n",
            "Epoch 168/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5535 - accuracy: 0.5965 - val_loss: 1.5945 - val_accuracy: 0.5672\n",
            "Epoch 169/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5566 - accuracy: 0.5940 - val_loss: 1.5919 - val_accuracy: 0.5672\n",
            "Epoch 170/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5208 - accuracy: 0.6041 - val_loss: 1.5894 - val_accuracy: 0.5672\n",
            "Epoch 171/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5441 - accuracy: 0.6029 - val_loss: 1.5869 - val_accuracy: 0.5714\n",
            "Epoch 172/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5380 - accuracy: 0.5790 - val_loss: 1.5844 - val_accuracy: 0.5714\n",
            "Epoch 173/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5365 - accuracy: 0.6494 - val_loss: 1.5825 - val_accuracy: 0.5714\n",
            "Epoch 174/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.5585 - accuracy: 0.6088 - val_loss: 1.5797 - val_accuracy: 0.5756\n",
            "Epoch 175/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.5398 - accuracy: 0.5967 - val_loss: 1.5768 - val_accuracy: 0.5714\n",
            "Epoch 176/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5141 - accuracy: 0.6292 - val_loss: 1.5747 - val_accuracy: 0.5714\n",
            "Epoch 177/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5095 - accuracy: 0.6022 - val_loss: 1.5729 - val_accuracy: 0.5714\n",
            "Epoch 178/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5070 - accuracy: 0.6146 - val_loss: 1.5709 - val_accuracy: 0.5714\n",
            "Epoch 179/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5446 - accuracy: 0.5931 - val_loss: 1.5685 - val_accuracy: 0.5672\n",
            "Epoch 180/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5514 - accuracy: 0.5880 - val_loss: 1.5663 - val_accuracy: 0.5714\n",
            "Epoch 181/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5538 - accuracy: 0.5873 - val_loss: 1.5633 - val_accuracy: 0.5672\n",
            "Epoch 182/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.5229 - accuracy: 0.6166 - val_loss: 1.5614 - val_accuracy: 0.5714\n",
            "Epoch 183/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5022 - accuracy: 0.6265 - val_loss: 1.5589 - val_accuracy: 0.5714\n",
            "Epoch 184/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5142 - accuracy: 0.6323 - val_loss: 1.5564 - val_accuracy: 0.5672\n",
            "Epoch 185/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5277 - accuracy: 0.6157 - val_loss: 1.5539 - val_accuracy: 0.5714\n",
            "Epoch 186/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.5172 - accuracy: 0.6066 - val_loss: 1.5524 - val_accuracy: 0.5630\n",
            "Epoch 187/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5119 - accuracy: 0.6280 - val_loss: 1.5498 - val_accuracy: 0.5672\n",
            "Epoch 188/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5151 - accuracy: 0.6117 - val_loss: 1.5480 - val_accuracy: 0.5714\n",
            "Epoch 189/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5092 - accuracy: 0.6148 - val_loss: 1.5460 - val_accuracy: 0.5546\n",
            "Epoch 190/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5096 - accuracy: 0.5899 - val_loss: 1.5434 - val_accuracy: 0.5630\n",
            "Epoch 191/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5331 - accuracy: 0.6010 - val_loss: 1.5408 - val_accuracy: 0.5630\n",
            "Epoch 192/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4949 - accuracy: 0.5960 - val_loss: 1.5389 - val_accuracy: 0.5588\n",
            "Epoch 193/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4847 - accuracy: 0.5929 - val_loss: 1.5371 - val_accuracy: 0.5546\n",
            "Epoch 194/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5071 - accuracy: 0.6109 - val_loss: 1.5353 - val_accuracy: 0.5630\n",
            "Epoch 195/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.4888 - accuracy: 0.5896 - val_loss: 1.5319 - val_accuracy: 0.5630\n",
            "Epoch 196/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4909 - accuracy: 0.6124 - val_loss: 1.5302 - val_accuracy: 0.5630\n",
            "Epoch 197/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4923 - accuracy: 0.6062 - val_loss: 1.5276 - val_accuracy: 0.5714\n",
            "Epoch 198/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4997 - accuracy: 0.5947 - val_loss: 1.5268 - val_accuracy: 0.5756\n",
            "Epoch 199/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4862 - accuracy: 0.6242 - val_loss: 1.5236 - val_accuracy: 0.5798\n",
            "Epoch 200/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4883 - accuracy: 0.6306 - val_loss: 1.5217 - val_accuracy: 0.5882\n",
            "Epoch 201/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4676 - accuracy: 0.6138 - val_loss: 1.5197 - val_accuracy: 0.5966\n",
            "Epoch 202/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4645 - accuracy: 0.6395 - val_loss: 1.5171 - val_accuracy: 0.5756\n",
            "Epoch 203/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4891 - accuracy: 0.6134 - val_loss: 1.5145 - val_accuracy: 0.5840\n",
            "Epoch 204/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4686 - accuracy: 0.6175 - val_loss: 1.5124 - val_accuracy: 0.5714\n",
            "Epoch 205/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4819 - accuracy: 0.6230 - val_loss: 1.5102 - val_accuracy: 0.5756\n",
            "Epoch 206/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4807 - accuracy: 0.6269 - val_loss: 1.5081 - val_accuracy: 0.5714\n",
            "Epoch 207/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4631 - accuracy: 0.6147 - val_loss: 1.5061 - val_accuracy: 0.5756\n",
            "Epoch 208/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4897 - accuracy: 0.6081 - val_loss: 1.5036 - val_accuracy: 0.5798\n",
            "Epoch 209/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4655 - accuracy: 0.6458 - val_loss: 1.5018 - val_accuracy: 0.5798\n",
            "Epoch 210/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4431 - accuracy: 0.6496 - val_loss: 1.4997 - val_accuracy: 0.5882\n",
            "Epoch 211/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4529 - accuracy: 0.6149 - val_loss: 1.4975 - val_accuracy: 0.5798\n",
            "Epoch 212/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4628 - accuracy: 0.6093 - val_loss: 1.4953 - val_accuracy: 0.5756\n",
            "Epoch 213/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4601 - accuracy: 0.6253 - val_loss: 1.4932 - val_accuracy: 0.5840\n",
            "Epoch 214/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4494 - accuracy: 0.6103 - val_loss: 1.4912 - val_accuracy: 0.5840\n",
            "Epoch 215/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4636 - accuracy: 0.6270 - val_loss: 1.4889 - val_accuracy: 0.5966\n",
            "Epoch 216/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4516 - accuracy: 0.6425 - val_loss: 1.4871 - val_accuracy: 0.5882\n",
            "Epoch 217/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4291 - accuracy: 0.6396 - val_loss: 1.4854 - val_accuracy: 0.5924\n",
            "Epoch 218/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4628 - accuracy: 0.6186 - val_loss: 1.4838 - val_accuracy: 0.5966\n",
            "Epoch 219/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4272 - accuracy: 0.6399 - val_loss: 1.4823 - val_accuracy: 0.5924\n",
            "Epoch 220/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3942 - accuracy: 0.6523 - val_loss: 1.4800 - val_accuracy: 0.5882\n",
            "Epoch 221/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4465 - accuracy: 0.6356 - val_loss: 1.4774 - val_accuracy: 0.5924\n",
            "Epoch 222/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4580 - accuracy: 0.6240 - val_loss: 1.4755 - val_accuracy: 0.5882\n",
            "Epoch 223/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4425 - accuracy: 0.6331 - val_loss: 1.4743 - val_accuracy: 0.5882\n",
            "Epoch 224/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.4454 - accuracy: 0.6154 - val_loss: 1.4720 - val_accuracy: 0.5924\n",
            "Epoch 225/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4213 - accuracy: 0.6442 - val_loss: 1.4694 - val_accuracy: 0.6008\n",
            "Epoch 226/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4376 - accuracy: 0.6402 - val_loss: 1.4666 - val_accuracy: 0.6008\n",
            "Epoch 227/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4521 - accuracy: 0.6340 - val_loss: 1.4649 - val_accuracy: 0.5966\n",
            "Epoch 228/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4385 - accuracy: 0.6205 - val_loss: 1.4627 - val_accuracy: 0.6050\n",
            "Epoch 229/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.4425 - accuracy: 0.6276 - val_loss: 1.4608 - val_accuracy: 0.6050\n",
            "Epoch 230/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4206 - accuracy: 0.6638 - val_loss: 1.4588 - val_accuracy: 0.6050\n",
            "Epoch 231/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4443 - accuracy: 0.6580 - val_loss: 1.4566 - val_accuracy: 0.6092\n",
            "Epoch 232/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4182 - accuracy: 0.6636 - val_loss: 1.4550 - val_accuracy: 0.5966\n",
            "Epoch 233/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3972 - accuracy: 0.6530 - val_loss: 1.4525 - val_accuracy: 0.5966\n",
            "Epoch 234/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4125 - accuracy: 0.6372 - val_loss: 1.4512 - val_accuracy: 0.5798\n",
            "Epoch 235/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.4411 - accuracy: 0.6243 - val_loss: 1.4491 - val_accuracy: 0.5924\n",
            "Epoch 236/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4262 - accuracy: 0.6575 - val_loss: 1.4471 - val_accuracy: 0.5924\n",
            "Epoch 237/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3715 - accuracy: 0.6856 - val_loss: 1.4452 - val_accuracy: 0.5966\n",
            "Epoch 238/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3974 - accuracy: 0.6865 - val_loss: 1.4435 - val_accuracy: 0.6008\n",
            "Epoch 239/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4207 - accuracy: 0.6412 - val_loss: 1.4413 - val_accuracy: 0.5966\n",
            "Epoch 240/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4131 - accuracy: 0.6610 - val_loss: 1.4397 - val_accuracy: 0.5924\n",
            "Epoch 241/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3959 - accuracy: 0.6662 - val_loss: 1.4373 - val_accuracy: 0.5924\n",
            "Epoch 242/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.3617 - accuracy: 0.6673 - val_loss: 1.4354 - val_accuracy: 0.5924\n",
            "Epoch 243/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.4030 - accuracy: 0.6355 - val_loss: 1.4331 - val_accuracy: 0.6050\n",
            "Epoch 244/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3927 - accuracy: 0.6991 - val_loss: 1.4314 - val_accuracy: 0.6092\n",
            "Epoch 245/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4066 - accuracy: 0.6868 - val_loss: 1.4288 - val_accuracy: 0.6134\n",
            "Epoch 246/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3864 - accuracy: 0.6597 - val_loss: 1.4263 - val_accuracy: 0.6050\n",
            "Epoch 247/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.4215 - accuracy: 0.6630 - val_loss: 1.4250 - val_accuracy: 0.5924\n",
            "Epoch 248/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3920 - accuracy: 0.6710 - val_loss: 1.4227 - val_accuracy: 0.5882\n",
            "Epoch 249/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3874 - accuracy: 0.6600 - val_loss: 1.4205 - val_accuracy: 0.6050\n",
            "Epoch 250/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3701 - accuracy: 0.6953 - val_loss: 1.4191 - val_accuracy: 0.6008\n",
            "Epoch 251/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3629 - accuracy: 0.6747 - val_loss: 1.4171 - val_accuracy: 0.5924\n",
            "Epoch 252/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3784 - accuracy: 0.6721 - val_loss: 1.4154 - val_accuracy: 0.5966\n",
            "Epoch 253/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3707 - accuracy: 0.6687 - val_loss: 1.4134 - val_accuracy: 0.6008\n",
            "Epoch 254/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3685 - accuracy: 0.6647 - val_loss: 1.4121 - val_accuracy: 0.5924\n",
            "Epoch 255/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3797 - accuracy: 0.6711 - val_loss: 1.4100 - val_accuracy: 0.6008\n",
            "Epoch 256/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3876 - accuracy: 0.6905 - val_loss: 1.4084 - val_accuracy: 0.5882\n",
            "Epoch 257/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3782 - accuracy: 0.6738 - val_loss: 1.4061 - val_accuracy: 0.5966\n",
            "Epoch 258/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3605 - accuracy: 0.6648 - val_loss: 1.4038 - val_accuracy: 0.5966\n",
            "Epoch 259/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3744 - accuracy: 0.6533 - val_loss: 1.4019 - val_accuracy: 0.6008\n",
            "Epoch 260/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3484 - accuracy: 0.6978 - val_loss: 1.4001 - val_accuracy: 0.6008\n",
            "Epoch 261/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3379 - accuracy: 0.6610 - val_loss: 1.3986 - val_accuracy: 0.6008\n",
            "Epoch 262/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3438 - accuracy: 0.6811 - val_loss: 1.3969 - val_accuracy: 0.6050\n",
            "Epoch 263/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3494 - accuracy: 0.6818 - val_loss: 1.3949 - val_accuracy: 0.6050\n",
            "Epoch 264/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3489 - accuracy: 0.6801 - val_loss: 1.3939 - val_accuracy: 0.6008\n",
            "Epoch 265/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3659 - accuracy: 0.6583 - val_loss: 1.3916 - val_accuracy: 0.6134\n",
            "Epoch 266/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3437 - accuracy: 0.6735 - val_loss: 1.3893 - val_accuracy: 0.6134\n",
            "Epoch 267/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3834 - accuracy: 0.6634 - val_loss: 1.3872 - val_accuracy: 0.6134\n",
            "Epoch 268/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3763 - accuracy: 0.6509 - val_loss: 1.3852 - val_accuracy: 0.6218\n",
            "Epoch 269/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3559 - accuracy: 0.6787 - val_loss: 1.3834 - val_accuracy: 0.6176\n",
            "Epoch 270/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3162 - accuracy: 0.6934 - val_loss: 1.3817 - val_accuracy: 0.6218\n",
            "Epoch 271/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3405 - accuracy: 0.6793 - val_loss: 1.3792 - val_accuracy: 0.6345\n",
            "Epoch 272/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3516 - accuracy: 0.6669 - val_loss: 1.3774 - val_accuracy: 0.6345\n",
            "Epoch 273/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3553 - accuracy: 0.6711 - val_loss: 1.3756 - val_accuracy: 0.6387\n",
            "Epoch 274/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3306 - accuracy: 0.7067 - val_loss: 1.3739 - val_accuracy: 0.6345\n",
            "Epoch 275/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2762 - accuracy: 0.7268 - val_loss: 1.3733 - val_accuracy: 0.6134\n",
            "Epoch 276/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3147 - accuracy: 0.6942 - val_loss: 1.3711 - val_accuracy: 0.6261\n",
            "Epoch 277/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3056 - accuracy: 0.6739 - val_loss: 1.3690 - val_accuracy: 0.6261\n",
            "Epoch 278/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.2869 - accuracy: 0.7012 - val_loss: 1.3672 - val_accuracy: 0.6345\n",
            "Epoch 279/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3525 - accuracy: 0.6650 - val_loss: 1.3656 - val_accuracy: 0.6303\n",
            "Epoch 280/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3526 - accuracy: 0.6704 - val_loss: 1.3638 - val_accuracy: 0.6303\n",
            "Epoch 281/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.3107 - accuracy: 0.7066 - val_loss: 1.3630 - val_accuracy: 0.6303\n",
            "Epoch 282/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3012 - accuracy: 0.6928 - val_loss: 1.3611 - val_accuracy: 0.6387\n",
            "Epoch 283/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3489 - accuracy: 0.6661 - val_loss: 1.3592 - val_accuracy: 0.6218\n",
            "Epoch 284/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3421 - accuracy: 0.6621 - val_loss: 1.3577 - val_accuracy: 0.6261\n",
            "Epoch 285/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.3078 - accuracy: 0.6810 - val_loss: 1.3554 - val_accuracy: 0.6387\n",
            "Epoch 286/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3000 - accuracy: 0.7045 - val_loss: 1.3537 - val_accuracy: 0.6387\n",
            "Epoch 287/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3106 - accuracy: 0.6855 - val_loss: 1.3521 - val_accuracy: 0.6387\n",
            "Epoch 288/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3358 - accuracy: 0.6881 - val_loss: 1.3504 - val_accuracy: 0.6345\n",
            "Epoch 289/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2792 - accuracy: 0.7091 - val_loss: 1.3487 - val_accuracy: 0.6429\n",
            "Epoch 290/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.3228 - accuracy: 0.6788 - val_loss: 1.3464 - val_accuracy: 0.6387\n",
            "Epoch 291/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.3063 - accuracy: 0.6734 - val_loss: 1.3453 - val_accuracy: 0.6429\n",
            "Epoch 292/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3104 - accuracy: 0.6818 - val_loss: 1.3437 - val_accuracy: 0.6471\n",
            "Epoch 293/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2941 - accuracy: 0.6975 - val_loss: 1.3430 - val_accuracy: 0.6176\n",
            "Epoch 294/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3004 - accuracy: 0.6736 - val_loss: 1.3400 - val_accuracy: 0.6513\n",
            "Epoch 295/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.3326 - accuracy: 0.6624 - val_loss: 1.3391 - val_accuracy: 0.6429\n",
            "Epoch 296/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3054 - accuracy: 0.6904 - val_loss: 1.3372 - val_accuracy: 0.6471\n",
            "Epoch 297/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2616 - accuracy: 0.7008 - val_loss: 1.3353 - val_accuracy: 0.6471\n",
            "Epoch 298/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2786 - accuracy: 0.6840 - val_loss: 1.3337 - val_accuracy: 0.6471\n",
            "Epoch 299/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3033 - accuracy: 0.6759 - val_loss: 1.3324 - val_accuracy: 0.6471\n",
            "Epoch 300/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2798 - accuracy: 0.7060 - val_loss: 1.3294 - val_accuracy: 0.6513\n",
            "Epoch 301/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3008 - accuracy: 0.6650 - val_loss: 1.3283 - val_accuracy: 0.6471\n",
            "Epoch 302/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3159 - accuracy: 0.6748 - val_loss: 1.3271 - val_accuracy: 0.6429\n",
            "Epoch 303/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2675 - accuracy: 0.7248 - val_loss: 1.3252 - val_accuracy: 0.6471\n",
            "Epoch 304/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.3180 - accuracy: 0.6746 - val_loss: 1.3233 - val_accuracy: 0.6555\n",
            "Epoch 305/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.2898 - accuracy: 0.6982 - val_loss: 1.3211 - val_accuracy: 0.6513\n",
            "Epoch 306/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2777 - accuracy: 0.7013 - val_loss: 1.3197 - val_accuracy: 0.6513\n",
            "Epoch 307/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2918 - accuracy: 0.6856 - val_loss: 1.3182 - val_accuracy: 0.6555\n",
            "Epoch 308/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.2667 - accuracy: 0.7136 - val_loss: 1.3166 - val_accuracy: 0.6471\n",
            "Epoch 309/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.2524 - accuracy: 0.7284 - val_loss: 1.3148 - val_accuracy: 0.6471\n",
            "Epoch 310/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.2808 - accuracy: 0.6856 - val_loss: 1.3131 - val_accuracy: 0.6471\n",
            "Epoch 311/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2940 - accuracy: 0.6752 - val_loss: 1.3114 - val_accuracy: 0.6513\n",
            "Epoch 312/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.2703 - accuracy: 0.7188 - val_loss: 1.3097 - val_accuracy: 0.6513\n",
            "Epoch 313/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2544 - accuracy: 0.7019 - val_loss: 1.3081 - val_accuracy: 0.6471\n",
            "Epoch 314/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2711 - accuracy: 0.6824 - val_loss: 1.3066 - val_accuracy: 0.6513\n",
            "Epoch 315/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2683 - accuracy: 0.6826 - val_loss: 1.3042 - val_accuracy: 0.6513\n",
            "Epoch 316/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2582 - accuracy: 0.7138 - val_loss: 1.3022 - val_accuracy: 0.6639\n",
            "Epoch 317/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2727 - accuracy: 0.7118 - val_loss: 1.3007 - val_accuracy: 0.6597\n",
            "Epoch 318/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2390 - accuracy: 0.7451 - val_loss: 1.2992 - val_accuracy: 0.6639\n",
            "Epoch 319/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.2445 - accuracy: 0.7238 - val_loss: 1.2978 - val_accuracy: 0.6639\n",
            "Epoch 320/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2585 - accuracy: 0.7444 - val_loss: 1.2962 - val_accuracy: 0.6597\n",
            "Epoch 321/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2619 - accuracy: 0.7220 - val_loss: 1.2948 - val_accuracy: 0.6597\n",
            "Epoch 322/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2393 - accuracy: 0.7317 - val_loss: 1.2934 - val_accuracy: 0.6639\n",
            "Epoch 323/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2454 - accuracy: 0.7178 - val_loss: 1.2921 - val_accuracy: 0.6555\n",
            "Epoch 324/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2358 - accuracy: 0.7441 - val_loss: 1.2908 - val_accuracy: 0.6597\n",
            "Epoch 325/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2342 - accuracy: 0.7346 - val_loss: 1.2895 - val_accuracy: 0.6555\n",
            "Epoch 326/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2273 - accuracy: 0.7364 - val_loss: 1.2871 - val_accuracy: 0.6639\n",
            "Epoch 327/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2594 - accuracy: 0.7169 - val_loss: 1.2860 - val_accuracy: 0.6681\n",
            "Epoch 328/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2698 - accuracy: 0.7093 - val_loss: 1.2854 - val_accuracy: 0.6555\n",
            "Epoch 329/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2147 - accuracy: 0.7297 - val_loss: 1.2831 - val_accuracy: 0.6639\n",
            "Epoch 330/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2560 - accuracy: 0.7287 - val_loss: 1.2815 - val_accuracy: 0.6639\n",
            "Epoch 331/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2079 - accuracy: 0.7523 - val_loss: 1.2799 - val_accuracy: 0.6639\n",
            "Epoch 332/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2272 - accuracy: 0.7293 - val_loss: 1.2789 - val_accuracy: 0.6639\n",
            "Epoch 333/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2437 - accuracy: 0.7285 - val_loss: 1.2766 - val_accuracy: 0.6681\n",
            "Epoch 334/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2237 - accuracy: 0.7329 - val_loss: 1.2745 - val_accuracy: 0.6765\n",
            "Epoch 335/500\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.2484 - accuracy: 0.7209 - val_loss: 1.2730 - val_accuracy: 0.6681\n",
            "Epoch 336/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2369 - accuracy: 0.7113 - val_loss: 1.2719 - val_accuracy: 0.6765\n",
            "Epoch 337/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2212 - accuracy: 0.7260 - val_loss: 1.2698 - val_accuracy: 0.6765\n",
            "Epoch 338/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2175 - accuracy: 0.7314 - val_loss: 1.2680 - val_accuracy: 0.6765\n",
            "Epoch 339/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2241 - accuracy: 0.7111 - val_loss: 1.2664 - val_accuracy: 0.6807\n",
            "Epoch 340/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2080 - accuracy: 0.7571 - val_loss: 1.2658 - val_accuracy: 0.6681\n",
            "Epoch 341/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2130 - accuracy: 0.7209 - val_loss: 1.2640 - val_accuracy: 0.6765\n",
            "Epoch 342/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1886 - accuracy: 0.7343 - val_loss: 1.2620 - val_accuracy: 0.6681\n",
            "Epoch 343/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1977 - accuracy: 0.7416 - val_loss: 1.2608 - val_accuracy: 0.6723\n",
            "Epoch 344/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2276 - accuracy: 0.7352 - val_loss: 1.2591 - val_accuracy: 0.6723\n",
            "Epoch 345/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2374 - accuracy: 0.7206 - val_loss: 1.2574 - val_accuracy: 0.6765\n",
            "Epoch 346/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2246 - accuracy: 0.7493 - val_loss: 1.2561 - val_accuracy: 0.6807\n",
            "Epoch 347/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2002 - accuracy: 0.7488 - val_loss: 1.2546 - val_accuracy: 0.6807\n",
            "Epoch 348/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1954 - accuracy: 0.7575 - val_loss: 1.2540 - val_accuracy: 0.6807\n",
            "Epoch 349/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2422 - accuracy: 0.7247 - val_loss: 1.2517 - val_accuracy: 0.6849\n",
            "Epoch 350/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1974 - accuracy: 0.7479 - val_loss: 1.2505 - val_accuracy: 0.6849\n",
            "Epoch 351/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1914 - accuracy: 0.7329 - val_loss: 1.2493 - val_accuracy: 0.6807\n",
            "Epoch 352/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.2022 - accuracy: 0.7332 - val_loss: 1.2483 - val_accuracy: 0.6765\n",
            "Epoch 353/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2478 - accuracy: 0.7418 - val_loss: 1.2470 - val_accuracy: 0.6765\n",
            "Epoch 354/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2103 - accuracy: 0.7497 - val_loss: 1.2453 - val_accuracy: 0.6891\n",
            "Epoch 355/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1953 - accuracy: 0.7481 - val_loss: 1.2435 - val_accuracy: 0.6849\n",
            "Epoch 356/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1789 - accuracy: 0.7696 - val_loss: 1.2419 - val_accuracy: 0.6765\n",
            "Epoch 357/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2064 - accuracy: 0.7406 - val_loss: 1.2400 - val_accuracy: 0.6765\n",
            "Epoch 358/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.1876 - accuracy: 0.7678 - val_loss: 1.2380 - val_accuracy: 0.6807\n",
            "Epoch 359/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.2210 - accuracy: 0.7593 - val_loss: 1.2367 - val_accuracy: 0.6765\n",
            "Epoch 360/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1889 - accuracy: 0.7686 - val_loss: 1.2348 - val_accuracy: 0.6975\n",
            "Epoch 361/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1876 - accuracy: 0.7936 - val_loss: 1.2338 - val_accuracy: 0.6849\n",
            "Epoch 362/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1765 - accuracy: 0.7742 - val_loss: 1.2326 - val_accuracy: 0.6807\n",
            "Epoch 363/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1921 - accuracy: 0.7501 - val_loss: 1.2311 - val_accuracy: 0.6807\n",
            "Epoch 364/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1800 - accuracy: 0.7757 - val_loss: 1.2307 - val_accuracy: 0.6765\n",
            "Epoch 365/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1568 - accuracy: 0.7593 - val_loss: 1.2281 - val_accuracy: 0.7059\n",
            "Epoch 366/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1664 - accuracy: 0.7672 - val_loss: 1.2270 - val_accuracy: 0.7059\n",
            "Epoch 367/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1879 - accuracy: 0.7832 - val_loss: 1.2261 - val_accuracy: 0.6933\n",
            "Epoch 368/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1694 - accuracy: 0.7784 - val_loss: 1.2246 - val_accuracy: 0.6975\n",
            "Epoch 369/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1621 - accuracy: 0.7761 - val_loss: 1.2232 - val_accuracy: 0.7017\n",
            "Epoch 370/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.1964 - accuracy: 0.7682 - val_loss: 1.2217 - val_accuracy: 0.7101\n",
            "Epoch 371/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1831 - accuracy: 0.7642 - val_loss: 1.2209 - val_accuracy: 0.7017\n",
            "Epoch 372/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1493 - accuracy: 0.7860 - val_loss: 1.2193 - val_accuracy: 0.7101\n",
            "Epoch 373/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1922 - accuracy: 0.7722 - val_loss: 1.2184 - val_accuracy: 0.7017\n",
            "Epoch 374/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1937 - accuracy: 0.7685 - val_loss: 1.2163 - val_accuracy: 0.7227\n",
            "Epoch 375/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1468 - accuracy: 0.7976 - val_loss: 1.2157 - val_accuracy: 0.7101\n",
            "Epoch 376/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1422 - accuracy: 0.8011 - val_loss: 1.2138 - val_accuracy: 0.7143\n",
            "Epoch 377/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.1715 - accuracy: 0.7809 - val_loss: 1.2123 - val_accuracy: 0.7185\n",
            "Epoch 378/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1388 - accuracy: 0.8086 - val_loss: 1.2105 - val_accuracy: 0.7311\n",
            "Epoch 379/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1962 - accuracy: 0.7807 - val_loss: 1.2089 - val_accuracy: 0.7479\n",
            "Epoch 380/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1637 - accuracy: 0.7870 - val_loss: 1.2079 - val_accuracy: 0.7353\n",
            "Epoch 381/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.2021 - accuracy: 0.7654 - val_loss: 1.2060 - val_accuracy: 0.7479\n",
            "Epoch 382/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1450 - accuracy: 0.8051 - val_loss: 1.2047 - val_accuracy: 0.7479\n",
            "Epoch 383/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1561 - accuracy: 0.8094 - val_loss: 1.2029 - val_accuracy: 0.7521\n",
            "Epoch 384/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1583 - accuracy: 0.7969 - val_loss: 1.2009 - val_accuracy: 0.7605\n",
            "Epoch 385/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1560 - accuracy: 0.8191 - val_loss: 1.2012 - val_accuracy: 0.7437\n",
            "Epoch 386/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1679 - accuracy: 0.7947 - val_loss: 1.1981 - val_accuracy: 0.7773\n",
            "Epoch 387/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1684 - accuracy: 0.7889 - val_loss: 1.1970 - val_accuracy: 0.7689\n",
            "Epoch 388/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1554 - accuracy: 0.8062 - val_loss: 1.1957 - val_accuracy: 0.7731\n",
            "Epoch 389/500\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 1.1634 - accuracy: 0.8081 - val_loss: 1.1943 - val_accuracy: 0.7731\n",
            "Epoch 390/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1392 - accuracy: 0.7999 - val_loss: 1.1938 - val_accuracy: 0.7731\n",
            "Epoch 391/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1315 - accuracy: 0.8161 - val_loss: 1.1920 - val_accuracy: 0.7605\n",
            "Epoch 392/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1470 - accuracy: 0.8084 - val_loss: 1.1909 - val_accuracy: 0.7605\n",
            "Epoch 393/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1468 - accuracy: 0.8070 - val_loss: 1.1899 - val_accuracy: 0.7647\n",
            "Epoch 394/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1501 - accuracy: 0.8127 - val_loss: 1.1878 - val_accuracy: 0.7689\n",
            "Epoch 395/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1693 - accuracy: 0.8070 - val_loss: 1.1858 - val_accuracy: 0.7731\n",
            "Epoch 396/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1515 - accuracy: 0.8063 - val_loss: 1.1849 - val_accuracy: 0.7773\n",
            "Epoch 397/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1346 - accuracy: 0.8022 - val_loss: 1.1841 - val_accuracy: 0.7689\n",
            "Epoch 398/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1451 - accuracy: 0.8048 - val_loss: 1.1827 - val_accuracy: 0.7731\n",
            "Epoch 399/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1150 - accuracy: 0.8053 - val_loss: 1.1808 - val_accuracy: 0.7689\n",
            "Epoch 400/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1570 - accuracy: 0.8281 - val_loss: 1.1794 - val_accuracy: 0.7731\n",
            "Epoch 401/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0903 - accuracy: 0.8392 - val_loss: 1.1778 - val_accuracy: 0.7689\n",
            "Epoch 402/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1029 - accuracy: 0.8246 - val_loss: 1.1759 - val_accuracy: 0.7647\n",
            "Epoch 403/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1213 - accuracy: 0.8084 - val_loss: 1.1754 - val_accuracy: 0.7731\n",
            "Epoch 404/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1117 - accuracy: 0.8309 - val_loss: 1.1734 - val_accuracy: 0.7689\n",
            "Epoch 405/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1263 - accuracy: 0.8264 - val_loss: 1.1724 - val_accuracy: 0.7689\n",
            "Epoch 406/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0962 - accuracy: 0.8151 - val_loss: 1.1714 - val_accuracy: 0.7731\n",
            "Epoch 407/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1032 - accuracy: 0.8248 - val_loss: 1.1698 - val_accuracy: 0.7731\n",
            "Epoch 408/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1601 - accuracy: 0.8054 - val_loss: 1.1703 - val_accuracy: 0.7731\n",
            "Epoch 409/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0965 - accuracy: 0.8191 - val_loss: 1.1683 - val_accuracy: 0.7731\n",
            "Epoch 410/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0918 - accuracy: 0.8229 - val_loss: 1.1666 - val_accuracy: 0.7731\n",
            "Epoch 411/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1172 - accuracy: 0.8261 - val_loss: 1.1654 - val_accuracy: 0.7731\n",
            "Epoch 412/500\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 1.1191 - accuracy: 0.8470 - val_loss: 1.1642 - val_accuracy: 0.7731\n",
            "Epoch 413/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1266 - accuracy: 0.8157 - val_loss: 1.1627 - val_accuracy: 0.7773\n",
            "Epoch 414/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1251 - accuracy: 0.8283 - val_loss: 1.1615 - val_accuracy: 0.7731\n",
            "Epoch 415/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1196 - accuracy: 0.8107 - val_loss: 1.1617 - val_accuracy: 0.7899\n",
            "Epoch 416/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.1512 - accuracy: 0.8165 - val_loss: 1.1597 - val_accuracy: 0.7941\n",
            "Epoch 417/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0888 - accuracy: 0.8325 - val_loss: 1.1584 - val_accuracy: 0.7941\n",
            "Epoch 418/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0917 - accuracy: 0.8334 - val_loss: 1.1581 - val_accuracy: 0.7899\n",
            "Epoch 419/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1465 - accuracy: 0.8195 - val_loss: 1.1559 - val_accuracy: 0.7941\n",
            "Epoch 420/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.1285 - accuracy: 0.8296 - val_loss: 1.1556 - val_accuracy: 0.7857\n",
            "Epoch 421/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1388 - accuracy: 0.8201 - val_loss: 1.1543 - val_accuracy: 0.7857\n",
            "Epoch 422/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1352 - accuracy: 0.8323 - val_loss: 1.1516 - val_accuracy: 0.7899\n",
            "Epoch 423/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1221 - accuracy: 0.8172 - val_loss: 1.1504 - val_accuracy: 0.7899\n",
            "Epoch 424/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1048 - accuracy: 0.8467 - val_loss: 1.1487 - val_accuracy: 0.7815\n",
            "Epoch 425/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0881 - accuracy: 0.8413 - val_loss: 1.1480 - val_accuracy: 0.7899\n",
            "Epoch 426/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0695 - accuracy: 0.8352 - val_loss: 1.1463 - val_accuracy: 0.7983\n",
            "Epoch 427/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.0921 - accuracy: 0.8495 - val_loss: 1.1454 - val_accuracy: 0.7941\n",
            "Epoch 428/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0924 - accuracy: 0.8314 - val_loss: 1.1469 - val_accuracy: 0.7899\n",
            "Epoch 429/500\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 1.1216 - accuracy: 0.8303 - val_loss: 1.1454 - val_accuracy: 0.7941\n",
            "Epoch 430/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1421 - accuracy: 0.8273 - val_loss: 1.1433 - val_accuracy: 0.7857\n",
            "Epoch 431/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0705 - accuracy: 0.8492 - val_loss: 1.1405 - val_accuracy: 0.7941\n",
            "Epoch 432/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0858 - accuracy: 0.8324 - val_loss: 1.1388 - val_accuracy: 0.7941\n",
            "Epoch 433/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0811 - accuracy: 0.8376 - val_loss: 1.1381 - val_accuracy: 0.7983\n",
            "Epoch 434/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0520 - accuracy: 0.8615 - val_loss: 1.1375 - val_accuracy: 0.7983\n",
            "Epoch 435/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0907 - accuracy: 0.8221 - val_loss: 1.1353 - val_accuracy: 0.8025\n",
            "Epoch 436/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0842 - accuracy: 0.8421 - val_loss: 1.1353 - val_accuracy: 0.7983\n",
            "Epoch 437/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0957 - accuracy: 0.8296 - val_loss: 1.1345 - val_accuracy: 0.8025\n",
            "Epoch 438/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0739 - accuracy: 0.8425 - val_loss: 1.1323 - val_accuracy: 0.7899\n",
            "Epoch 439/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0822 - accuracy: 0.8415 - val_loss: 1.1303 - val_accuracy: 0.7983\n",
            "Epoch 440/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0943 - accuracy: 0.8376 - val_loss: 1.1283 - val_accuracy: 0.8025\n",
            "Epoch 441/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0811 - accuracy: 0.8446 - val_loss: 1.1297 - val_accuracy: 0.7983\n",
            "Epoch 442/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0607 - accuracy: 0.8423 - val_loss: 1.1271 - val_accuracy: 0.7899\n",
            "Epoch 443/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0909 - accuracy: 0.8280 - val_loss: 1.1246 - val_accuracy: 0.8067\n",
            "Epoch 444/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.0841 - accuracy: 0.8429 - val_loss: 1.1237 - val_accuracy: 0.7983\n",
            "Epoch 445/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0557 - accuracy: 0.8377 - val_loss: 1.1232 - val_accuracy: 0.7941\n",
            "Epoch 446/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0797 - accuracy: 0.8364 - val_loss: 1.1222 - val_accuracy: 0.7983\n",
            "Epoch 447/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0775 - accuracy: 0.8233 - val_loss: 1.1210 - val_accuracy: 0.8067\n",
            "Epoch 448/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0582 - accuracy: 0.8517 - val_loss: 1.1197 - val_accuracy: 0.8067\n",
            "Epoch 449/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0754 - accuracy: 0.8447 - val_loss: 1.1185 - val_accuracy: 0.8067\n",
            "Epoch 450/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0736 - accuracy: 0.8440 - val_loss: 1.1176 - val_accuracy: 0.8067\n",
            "Epoch 451/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0682 - accuracy: 0.8459 - val_loss: 1.1175 - val_accuracy: 0.8151\n",
            "Epoch 452/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0699 - accuracy: 0.8302 - val_loss: 1.1179 - val_accuracy: 0.7941\n",
            "Epoch 453/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0567 - accuracy: 0.8541 - val_loss: 1.1138 - val_accuracy: 0.8067\n",
            "Epoch 454/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0349 - accuracy: 0.8596 - val_loss: 1.1124 - val_accuracy: 0.8025\n",
            "Epoch 455/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0616 - accuracy: 0.8598 - val_loss: 1.1128 - val_accuracy: 0.7983\n",
            "Epoch 456/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0814 - accuracy: 0.8404 - val_loss: 1.1125 - val_accuracy: 0.8025\n",
            "Epoch 457/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0778 - accuracy: 0.8313 - val_loss: 1.1105 - val_accuracy: 0.8025\n",
            "Epoch 458/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0524 - accuracy: 0.8415 - val_loss: 1.1100 - val_accuracy: 0.8067\n",
            "Epoch 459/500\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.0484 - accuracy: 0.8459 - val_loss: 1.1083 - val_accuracy: 0.8025\n",
            "Epoch 460/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0739 - accuracy: 0.8300 - val_loss: 1.1063 - val_accuracy: 0.8067\n",
            "Epoch 461/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0636 - accuracy: 0.8612 - val_loss: 1.1052 - val_accuracy: 0.8025\n",
            "Epoch 462/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0339 - accuracy: 0.8513 - val_loss: 1.1029 - val_accuracy: 0.8109\n",
            "Epoch 463/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0489 - accuracy: 0.8375 - val_loss: 1.1026 - val_accuracy: 0.8151\n",
            "Epoch 464/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0350 - accuracy: 0.8618 - val_loss: 1.1014 - val_accuracy: 0.8109\n",
            "Epoch 465/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0687 - accuracy: 0.8393 - val_loss: 1.1014 - val_accuracy: 0.8109\n",
            "Epoch 466/500\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 1.0589 - accuracy: 0.8381 - val_loss: 1.1001 - val_accuracy: 0.8235\n",
            "Epoch 467/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0542 - accuracy: 0.8315 - val_loss: 1.1000 - val_accuracy: 0.8067\n",
            "Epoch 468/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0562 - accuracy: 0.8225 - val_loss: 1.0977 - val_accuracy: 0.8109\n",
            "Epoch 469/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0550 - accuracy: 0.8285 - val_loss: 1.0952 - val_accuracy: 0.8067\n",
            "Epoch 470/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0863 - accuracy: 0.8167 - val_loss: 1.0942 - val_accuracy: 0.8067\n",
            "Epoch 471/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0461 - accuracy: 0.8543 - val_loss: 1.0930 - val_accuracy: 0.8067\n",
            "Epoch 472/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.0328 - accuracy: 0.8397 - val_loss: 1.0925 - val_accuracy: 0.8109\n",
            "Epoch 473/500\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 1.0504 - accuracy: 0.8502 - val_loss: 1.0918 - val_accuracy: 0.8109\n",
            "Epoch 474/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0180 - accuracy: 0.8505 - val_loss: 1.0915 - val_accuracy: 0.8025\n",
            "Epoch 475/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0505 - accuracy: 0.8397 - val_loss: 1.0899 - val_accuracy: 0.8109\n",
            "Epoch 476/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0631 - accuracy: 0.8285 - val_loss: 1.0907 - val_accuracy: 0.8067\n",
            "Epoch 477/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0260 - accuracy: 0.8570 - val_loss: 1.0893 - val_accuracy: 0.8025\n",
            "Epoch 478/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0411 - accuracy: 0.8304 - val_loss: 1.0881 - val_accuracy: 0.8067\n",
            "Epoch 479/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0686 - accuracy: 0.8327 - val_loss: 1.0864 - val_accuracy: 0.8067\n",
            "Epoch 480/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0491 - accuracy: 0.8302 - val_loss: 1.0852 - val_accuracy: 0.8067\n",
            "Epoch 481/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0151 - accuracy: 0.8623 - val_loss: 1.0835 - val_accuracy: 0.8067\n",
            "Epoch 482/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0306 - accuracy: 0.8346 - val_loss: 1.0828 - val_accuracy: 0.8067\n",
            "Epoch 483/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0416 - accuracy: 0.8292 - val_loss: 1.0823 - val_accuracy: 0.8067\n",
            "Epoch 484/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.0121 - accuracy: 0.8489 - val_loss: 1.0804 - val_accuracy: 0.8109\n",
            "Epoch 485/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.9966 - accuracy: 0.8531 - val_loss: 1.0801 - val_accuracy: 0.8109\n",
            "Epoch 486/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.9675 - accuracy: 0.8642 - val_loss: 1.0801 - val_accuracy: 0.8067\n",
            "Epoch 487/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0334 - accuracy: 0.8430 - val_loss: 1.0763 - val_accuracy: 0.8109\n",
            "Epoch 488/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0621 - accuracy: 0.8389 - val_loss: 1.0763 - val_accuracy: 0.8025\n",
            "Epoch 489/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0221 - accuracy: 0.8484 - val_loss: 1.0773 - val_accuracy: 0.8151\n",
            "Epoch 490/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0133 - accuracy: 0.8515 - val_loss: 1.0757 - val_accuracy: 0.8151\n",
            "Epoch 491/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0248 - accuracy: 0.8471 - val_loss: 1.0726 - val_accuracy: 0.8193\n",
            "Epoch 492/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0604 - accuracy: 0.8427 - val_loss: 1.0721 - val_accuracy: 0.8193\n",
            "Epoch 493/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.9990 - accuracy: 0.8562 - val_loss: 1.0708 - val_accuracy: 0.8025\n",
            "Epoch 494/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0085 - accuracy: 0.8384 - val_loss: 1.0691 - val_accuracy: 0.8025\n",
            "Epoch 495/500\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.0355 - accuracy: 0.8359 - val_loss: 1.0680 - val_accuracy: 0.8067\n",
            "Epoch 496/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0485 - accuracy: 0.8434 - val_loss: 1.0674 - val_accuracy: 0.8151\n",
            "Epoch 497/500\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.0278 - accuracy: 0.8588 - val_loss: 1.0689 - val_accuracy: 0.8067\n",
            "Epoch 498/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0285 - accuracy: 0.8371 - val_loss: 1.0662 - val_accuracy: 0.8067\n",
            "Epoch 499/500\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.0352 - accuracy: 0.8307 - val_loss: 1.0641 - val_accuracy: 0.8067\n",
            "Epoch 500/500\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0238 - accuracy: 0.8266 - val_loss: 1.0638 - val_accuracy: 0.8109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ETHtE9UBMMv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dd4a7c5e-5c5f-4b72-cf2a-f233a912111d"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Testing accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVbeRt4Fb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "868d2f01-7ba3-4388-834b-84894658022e"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Testing accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oGRxisk9Xy9"
      },
      "source": [
        "class NetVlad(Layer):\n",
        "    def __init__(self, n_centers, output_dim, **kwargs):\n",
        "        self.n_centers = n_centers\n",
        "        self.output_dim = output_dim\n",
        "        super(NetVlad, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        try:\n",
        "            assert len(input_shape) == 3\n",
        "        except:\n",
        "            raise ValueError('Input should have shape (batch_size, time_steps, dims)')\n",
        "            \n",
        "        self.centers = self.add_weight(name='centers',\n",
        "                                       shape=(self.n_centers, input_shape[-1]),\n",
        "                                       initializer='uniform', \n",
        "                                       trainable=True\n",
        "                                      )\n",
        "        self.weight = self.add_weight(name='weight',\n",
        "                                       shape=(input_shape[-1], self.n_centers),\n",
        "                                       initializer='glorot_uniform', \n",
        "                                       trainable=True\n",
        "                                      )\n",
        "        self.bias = self.add_weight(name='bias',\n",
        "                                    shape=(self.n_centers,),\n",
        "                                    initializer='zeros', \n",
        "                                    trainable=True\n",
        "                                   )\n",
        "        self.reduc_dim = self.add_weight(name='reduc_dim',\n",
        "                                         shape=(input_shape[-1]*self.n_centers, self.output_dim),\n",
        "                                         initializer='zeros', \n",
        "                                         trainable=True\n",
        "                                        )\n",
        "        super(NetVlad, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # X is shape (bsize, time_steps, input_size)\n",
        "        # Get weights: shape=(bsize, time_steps, n_centers)\n",
        "        centers_weight = K.softmax(K.dot(x, self.weight) + self.bias)\n",
        "        assert centers_weight.shape[2] == self.n_centers\n",
        "        assert centers_weight.shape[1] == x.shape[1]\n",
        "        \n",
        "        # Agg by cluster: shape=(bsize, n_centers, input_size)\n",
        "        x_agg_clusters = K.batch_dot(centers_weight, x, axes=1)\n",
        "        \n",
        "        # Sum weights ad repeates in time dimension shape=(bsize, input_size, n_centers)\n",
        "        sum_weights = K.sum(centers_weight, axis=1)        \n",
        "        repeat_weights = K.repeat(sum_weights, x.shape[-1])\n",
        "        # transpose to dim (bsize, n_centers, input_size)\n",
        "        repeat_weights = K.permute_dimensions(repeat_weights,\n",
        "                                              pattern=(0,2,1))\n",
        "        # get full representation and flatten\n",
        "        full_rep = x_agg_clusters - repeat_weights * self.centers\n",
        "        full_rep = K.l2_normalize(full_rep, axis=-1)\n",
        "        full_rep = K.reshape(full_rep, shape=(-1, self.n_centers * x.shape[2].value))\n",
        "        full_rep = K.l2_normalize(full_rep, axis=-1)\n",
        "        # Reduce dimension\n",
        "        result = K.dot(full_rep, self.reduc_dim)\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0],self.output_dim)   \n",
        "\n",
        "def netvlad_model():\n",
        "    in_ = Input(shape=(4,2048), name='img')\n",
        "    \n",
        "    rep = NetVlad(n_centers=32, output_dim=2048)(in_)  \n",
        "    rep = Dropout(0.2)(rep)\n",
        "    \n",
        "    # context gating\n",
        "    gate = Dense(2048, activation='sigmoid')(rep)\n",
        "    rep = Multiply()([gate, rep])\n",
        "    \n",
        "    out_ = Dense(5270, activation='softmax', name='target')(rep)\n",
        "    model = Model([in_], [out_]) \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icyTyIz-O9IB"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(227,227,3)))\n",
        "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    \n",
        "    \n",
        "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    \n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))    \n",
        "\n",
        "m)odel.add(netvlad_model()\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(4096, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(4096, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(11, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl4W0j3a_8yF",
        "outputId": "3065b630-040a-4d84-f4bb-282212c1d1c6"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.optimizers.SGD(lr=0.0001),\n",
        "    metrics=['accuracy']    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2xhpoHcAFME",
        "outputId": "436bf77c-c31c-466c-fc64-009e75fdc3ff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 225, 225, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 225, 225, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 55, 55, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 55, 55, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 55, 55, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 27, 27, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 27, 27, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 27, 27, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 512)       0         \n",
            "=================================================================\n",
            "Total params: 7,635,264\n",
            "Trainable params: 7,635,264\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0GFu_2bA8MX",
        "outputId": "d4a31d26-231a-4214-95cd-10ded7ad94f9"
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "          epochs=50,\n",
        "          validation_data=val_ds,\n",
        "          validation_freq=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}